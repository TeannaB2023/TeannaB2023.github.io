<!DOCTYPE html>
<html lang= "en-US">
<head>
	<style type="text/css">
		h1, h2 {
		font-family: "Impact", Charcoal, sans-serif;
		color:#626160;
		}
		p {
			margin: 25px 50px 75px 100px;
			font-size: 20px;
			text-indent: 50px;
		}
		body{
		background-color: #FFFDF9;
		}	
	</style>
</head>
<body>
	<h1 style = "text-align:center">Data for Life</h1>
	<h2 style= "text-align: center">Third Essay</h2>
	<p>
	The city of New Orleans (NOLA) is known to have one of the highest rates of gun violence in the nation. The local government, including the mayoral office and the New Orleans Police Department (NOPD), identify gang and drug violence as the central mechanisms that yield these concerningly high homicide rates. City officials were urgently searching for any way to lower homicide rates in New Orleans. In 2012, the office of Mayor Mitch Landrieu believed they finally found the solution. Palantir, a data-mining firm that is funded by the CIA and one of the most valuable companies in Silicon Valley, was looking to test their new predictive policing software (Winston). In its inception, the partnership between the local government and the privately funded company seemed to the perfect solution. With Palantir’s LexisNexis’ Accurint software, the New Orleans government would receive a list of residents who are predicted to be involved in instances of gun violence (Winston). Furthermore, this technological insight would not cost the NOLA taxpayer a dollar; the program would be established by Palantir and subsequently funded by private donations. In exchange, the city government would only have to give Palantir uninhibited access to all of its residents’ data. Today, a year since the 6-year partnership, the CeaseFire was terminated after enormous public-backlash, and NOLA’s homicide rate is still one of the highest in the nation. Instead of solving a problem, the Palantir partnership introduced a new fundamental dilemma to NOLA: data privacy violations.
</p>
	<br>
	<p>
	After millions of dollars in investment, the CeaseFire program was found to have made no statistically significant reduction in the homicide rate according to the University of Cincinnati professor Nick Corsaro (Winston). However, the ultimate failure of the program was not what shamed it into obsolescence. The entitled secrecy and the dehumanizing destruction of individuals’ privacy are what hindered any meaningful change. Firstly, throughout the whole six-year partnership, the residents of NOLA and the majority of the city council were completely unaware of the program even though Palantir’s project completely relied on the scrapping of data from social media posts, police files, and government records. One Palantir associate stated that “no one in New Orleans even knows about this, to my knowledge.” (Winston). Since the program was externally funded and the pet project of the mayor, Palantir didn’t have to answer to anyone as they pulled personal data from thousands of residents. 
</p>
	<br>
	<p>
	As a result, Palantir’s software produced a list of about 3,900 residents who were predicted to be involved in acts of gun violence. With this processed information, Mayor Landrieu created a multi-departmental task force to approach the identified individuals. The officials would call in these residents and encourage them to join the CeaseFire campaign, which offered social programs like GED classes and employment referrals. However, if these targeted people were caught committing any crime, they would be served with the highest punishment. Although this program was intended to have a two-pronged approach, there was a disproportionate emphasis on criminal justice. After only conducting three call-ins, none of the participants completed their GED courses and 10% gained employment. On the other hand, 16% of the willing participants were detained by the NOPD. Furthermore, the list was used to arrest 83 individuals for racketeering, murder, and armed robbery (Winston). The punitive outcomes of the list of 3,900 reveal that the Palantir-NOLA partnership wasn’t made to save a city from gun violence. Rather, the data analysis findings were used as pieces of evidence that would permit the of capturing suspected criminals. Under the protection of secrecy, the CeaseFire program was able to take individuals’ data without having to answer to the Constitution, elected city officials, or the marginalized populations of NOLA.
</p>
	<br>
	<p>
	When small, online technology news sites, such as The Verge, brought Palantir’s actions into the light, these journalists opened a discussion about how the rights of NOLA residents were violated. A pivotal voice in this discussion is Kentrell Hickerson, one of the 83 people convicted in the CeaseFire gang bust (Johansson). His defense attorneys filed a motion that purports that evidence used against Hickerson violated his constitutional rights because Palantir’s evidence was based on data that Hickerson did not consent to be collected. Furthermore, his attorneys were never made aware of where the evidence came from and the judge never authorized the data collection, as well. Although the motion was just filed, the violation of privacy rights is not a new topic in the realm of predictive policing.
</p>
	<br>
	<p>
	Since the word was coined back in 2009, lawyers, civil rights advocates, and academics have called for the regulation of predictive policing. Shima Baradaran, a Brigham Young University law professor, stated that one of the biggest concerns in the emerging technology of predictive policing was the possible Fourth Amendment violations (Gordon). If predictive policing data would give police the license to unfairly target minority communities or deny a defendant’s right to a fair trial, then U.S. citizens wouldn’t be equally protected under the law. From the very beginning, transparency was regarded as the answer to these constitutional concerns. For example, a report by the National Institute of Justice stressed that policies need to be made to restrict how data is collected and shared by government organizations (Gordon). Additionally, law experts such as Professor Andrew Guthrie Ferguson of the University of the District of Columbia have stressed that “there must be transparency and accountability” to “police the predictive policing.” (Gordon). Even though this solution has been touted for years, it’s clear that companies like Palantir have taken the opposite approach in their implementations of predictive policing. The ardent dismissal of transparency has not just led to the violation of Americans’ rights, but the physical imprisonment of New Orleans residents. The only way for NOLA’s CeaseFire program to be redeemed is if the larger community can see how the program functions and work together to address the reasonable privacy concerns it poses. 
</p>
	<br>
	<p>
	In current New Orleans, with Palantir kicked out of the city and Mayor Landrieu kicked out of office, the new mayor, LaToya Cantrell, is building an initiative to reduce gun violence in NOLA (Stein and Maldonado). Unfortunately, the early concepts of her program are eerily familiar to the predictive policing tactics of Palantir. However, there is a markedly different foundation for her program: transparency. Instead of working with private tech companies, the city has reached out to the academic researcher referred to as the originator of predictive policing, Dr. Andrew Papachristos of Northwestern University (Stein and Maldonado). Although the software has not been created yet, he has pushed for community involvement in the process of building the program. After witnessing countless companies use his theories to marginalize minority communities, he is dedicated to turning a new leaf and producing less destructive outcomes with his research. But as the Palantir’s “NOLA Style” software moves to countries such as Denmark and Israel to identify potential terrorists, a more widespread movement towards transparency is required in the industry of predictive policing. 
</p>
	<br>
	
	<h2 style= "text-align:center">Works Cited</h2>
	<br>
	<p>
	Johansson, Anna. “5 Lessons Learned from the Predictive Policing Failure in New Orleans.” VentureBeat, VentureBeat, 20 Mar. 2018, venturebeat.com/2018/03/19/5-lessons-learned-from-the-predictive-policing-failure-in-new-orleans/.
	</p>
	<br>
	<p>
	Stein, Isaac, and Charles Maldonado. “Months after End of 'Predictive Policing' Contract, Cantrell Administration Works on New Tool to ID 'High-Risk' Residents.” The Lens, The Lens, 22 Feb. 2019, thelensnola.org/2018/10/24/months-after-end-of-predictive-policing-contract-cantrell-administration-works-on-new-tool-to-id-high-risk-residents/.
	</p>
	<br>
	<p>
	Winston, Ali. “Palantir Has Secretly Been Using New Orleans to Test Its Predictive Policing Technology.” The Verge, The Verge, 27 Feb. 2018, www.theverge.com/2018/2/27/17054740/palantir-predictive-policing-tool-new-orleans-nopd.
	</p>
</body>
</html>